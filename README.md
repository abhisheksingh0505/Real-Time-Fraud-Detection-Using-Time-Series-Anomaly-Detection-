
# ğŸš¨ Real-Time Fraud Detection Using Time Series Anomaly Detection

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Machine Learning](https://img.shields.io/badge/ML-Fraud_Detection-orange)]()
[![Deep Learning](https://img.shields.io/badge/DL-LSTM%2CAutoencoder-brightgreen)]()

## ğŸ“˜ Abstract

As the world goes digital, online transactions are more susceptible to fraud. Traditional rule-based systems struggle to detect sophisticated fraud patterns. This project introduces a **real-time fraud detection system** using machine learning and deep learning techniques such as:

- âœ… **Random Forest Classifier**
- ğŸ“ˆ **ARIMA for time-series forecasting**
- ğŸŒ² **Isolation Forest for unsupervised anomaly detection**
- ğŸ” **LSTM for sequential pattern recognition**
- ğŸ¤– **Autoencoders for deep anomaly detection**

---

## ğŸ“Š Dataset Details

- **Source**: Real transaction data
- **Features**: 
  - Transaction Type
  - Amount
  - Pre/Post Balance
  - Fraud Flags (isFraud, isFlaggedFraud)
- **Preprocessing**:
  - Missing Value Imputation
  - Label Encoding
  - Feature Scaling (StandardScaler / MinMaxScaler)
  - Time-Series Generation with Datetime Index

---

## ğŸ” Methodology

### ğŸ§¼ Data Preparation
- Clean and preprocess the dataset
- Encode categorical variables
- Normalize numerical features
- Handle class imbalance

### âš™ï¸ Model Implementation
| Model | Type | Purpose |
|-------|------|---------|
| ğŸ¯ Random Forest | Supervised | Classifies fraudulent transactions |
| ğŸ“Š ARIMA | Time-Series | Predicts anomalies over time |
| ğŸŒ² Isolation Forest | Unsupervised | Detects statistical outliers |
| ğŸ” LSTM | Deep Learning | Identifies sequential patterns |
| ğŸ¤– Autoencoders | Deep Learning | Flags anomalies by reconstruction error |

### ğŸš€ Real-Time Deployment
- Integrated into streaming pipelines
- Processes transactions with low latency
- Adaptive to evolving patterns

---

## ğŸ“ˆ Results

| Model         | Accuracy | Recall | FPR  | Latency |
|---------------|----------|--------|------|---------|
| ğŸ” LSTM        | **98.5%** | 95.2%  | 2.1% | 0.02s   |
| ğŸ¤– Autoencoder | 97.8%    | 93.7%  | Low  | 0.03s   |
| ğŸ“Š ARIMA       | 96.3%    | Moderate | Low | 0.04s   |

> **ğŸ† Best Performer**: LSTM (High accuracy + Real-time performance)

---

## ğŸ“š Literature Support

- Lee et al. â€“ Time Series Anomaly Detection using LSTM
- Ren et al. â€“ Microsoftâ€™s Anomaly Detection service
- Chen et al. â€“ Sensor-Drift-Aware Detection
- Aggarwal et al. â€“ LSTM on US Export-Import data

---

## ğŸ›  Tools & Technologies

- **Python** (Pandas, NumPy, Sklearn, TensorFlow, Keras)
- **Time-Series Analysis** (ARIMA, Isolation Forest)
- **Deep Learning** (LSTM, Autoencoders)
- **Deployment** (Streaming pipelines for real-time detection)

---

## ğŸ§  Future Enhancements

- Introduce **Transformer models** for long-term pattern learning
- Automate **hyperparameter tuning**
- Expand dataset diversity to enhance generalization

---

## ğŸ‘¨â€ğŸ’» Authors

- **Omkar Singh** â€“ Coordinator, Data Science
- **Swati Singh** â€“ Assistant Professor
- **Abhishek Singh** â€“ PG Student, Data Science
- **Vishal Pandey** â€“ PG Student, Data Science

ğŸ“« Contact: `omkarsingh@tcsc.edu.in` | `swatisingh2466@gmail.com` | `singh0505330@gmail.com` | `vishalpandey0266@gmail.com`

---



